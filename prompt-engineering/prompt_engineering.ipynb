{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dIQ9VN7DQQdU"
   },
   "source": [
    "##Prompt Engineering\n",
    "\n",
    "***Introduction***\n",
    "\n",
    "In this notebook, we are going to show how we can prompt engineer LLMs to analyze the text, from Discovery, according to our need. This notebook is intended as a starting point, showing two examples of prompt engineering, with the goal that you can then apply the same techniques to other analysis requirements.\n",
    "\n",
    "We will start by importing and installing required libraries. We will be using OpenAI library. Using OpenAI's API we will be using GPT-3.5. To use the API we will need OpenAI's API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z-lVwESg067L",
    "outputId": "1e8d78fe-8915-41cf-b652-481903fb8d5b"
   },
   "outputs": [],
   "source": [
    "%pip install -q openai\n",
    "%pip install -q requests\n",
    "%pip install -q json\n",
    "import json\n",
    "import re\n",
    "import requests\n",
    "from openai import OpenAI\n",
    "import helper_functions as hf\n",
    "client = OpenAI(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "07Kpgz4hRQQu"
   },
   "source": [
    "## **Document classification**\n",
    "\n",
    "Text classification is the task of Natural Language Processing (NLP) in which text/document is assigned to one or more classes or categories. However, for this task, the classes/categories have to be pre-defined as a label to which the texts are classified. In the scenario in which we have a set of descriptions but no labels, we can use LLMS to classify the required text to those descriptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L8UWkoEvVCeA"
   },
   "source": [
    "We will first define the set of descriptions to which we want our texts to be classified. For this, we will use the Collections description from Discovery. We will use Discovery API as shown in [Discovery API notebook](https://github.com/rae-drt/tna-exploratory-notebooks/blob/main/1-intro-to-discovery-api.ipynb). We will use a list of default ids for which we will request the description. If you want to add to the list some other record series, add their ids in the input box as a list like separated by a comma for example ['123', '124', '125']. If not, just press enter in the input box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E8T-peO0UAHL",
    "outputId": "59f1e37e-3ff8-47de-a6d9-7d001d957d0d"
   },
   "outputs": [],
   "source": [
    "documentIDs = ['C13519', 'C13520', 'C13522']\n",
    "inputArray = input(\"Please enter the list of record series IDs\")\n",
    "if inputArray:\n",
    "  hf.append_IDs(documentIDs, inputArray)\n",
    "print(\"The list of records are:\", documentIDs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HfMUWWSUXX6T"
   },
   "source": [
    "Now we will use Discovery API to fetch their descriptions and store them in the 'documents' dictionary with the key as the title of the record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pB4DQWD4KwST",
    "outputId": "531ec4f7-f1d3-45a2-f8df-765c0a6c9806"
   },
   "outputs": [],
   "source": [
    "documents = hf.populate_documents(documentIDs)\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w2we-BrdVKKk"
   },
   "source": [
    "We will now define the set of texts we want to classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Rfch1LwM5Tb",
    "outputId": "1b94863e-e608-4f9c-9e69-e1a72c48e112"
   },
   "outputs": [],
   "source": [
    "textIDs = ['C3411937', 'C12215981', 'C5485074', 'C5485055']\n",
    "inputArray = input(\"Please enter the list of record IDs\")\n",
    "if inputArray:\n",
    "  hf.append_IDs(textIDs, inputArray)\n",
    "print(\"The list of records are:\", textIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "miS8R0JLuMYF",
    "outputId": "ce4ae308-cdb2-4bfd-cb2c-78d3326e103f"
   },
   "outputs": [],
   "source": [
    "texts = hf.populate_texts(textIDs)\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M4R1kNEDVZ3z"
   },
   "source": [
    "Now we will send this to GPT using the required prompt. For this, we first tell the system what its role is. Here, its role is being a helpful assistant. Now, we will pass the set of documents followed by the text with the prompt. In the prompt, we ask the GPT just to classify the text and then return the result in JSON schema {'text': text, 'category':value} so that it can be computationally processed. For this example, since we haven't passed the labels, it will create its own set of labels to which the documents closely associate and classify to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "te6J9LTTIpMX",
    "outputId": "ee95a853-747d-4683-b65e-3fe4bf0adc0a"
   },
   "outputs": [],
   "source": [
    "for text in texts:\n",
    "  response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "      {\"role\": \"user\", \"content\": \"Classify and return as JSON the text '\" + text + \"'. Format in the following JSON schema {'text': text, 'category':value}\"}\n",
    "    ]\n",
    "  )\n",
    "\n",
    "  response_json = json.loads(response.choices[0].message.content)\n",
    "  print(response_json[\"text\"] + \": \" + response_json[\"category\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WMG20wYlvFpu"
   },
   "source": [
    "In the following prompt we ask the GPT to classify the text to one of the documents in the previously passed set and then return the result in JSON schema {'text': text, 'category':value}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MS6Shgm1V-kb",
    "outputId": "ac58c744-6e81-41ef-9fa3-6b8fd790e8e1"
   },
   "outputs": [],
   "source": [
    "for text in texts:\n",
    "  response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "      {\"role\": \"user\", \"content\": \"The set of documents are: \" + str(documents)},\n",
    "      {\"role\": \"user\", \"content\": \"Classify and return as JSON the text '\" + text + \"' to one of the documents given above. Format in the following JSON schema {'text': text, 'category':value}\"}\n",
    "    ]\n",
    "  )\n",
    "\n",
    "  response_json = json.loads(response.choices[0].message.content)\n",
    "  print(response_json[\"text\"] + \": \" + response_json[\"category\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eALP7Z_9woNg"
   },
   "source": [
    "This classified the texts to the documents as required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TWAy_xbLobxv"
   },
   "source": [
    "## **Sensitivity classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3DOvfa-woqFP"
   },
   "source": [
    "Sensitivity classification is a task of NLP in which a text is binary (two classes) classified into \"sensitive\" and \"not sensitive\" depending upon the factors: text contains personal information, and text is offensive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AbHE3Dpk6sqt"
   },
   "source": [
    "We now classify the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qpy35C73on8H",
    "outputId": "e3c31479-1f45-40f6-e60a-18227597d46f"
   },
   "outputs": [],
   "source": [
    "for text in texts:\n",
    "  response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "      {\"role\": \"user\", \"content\": \"Classify as sensitive or not the text '\" + text + \"'. Format in the following JSON schema {'text': text, 'classification':value, 'reason':value}\"}\n",
    "    ]\n",
    "  )\n",
    "  print(response.choices[0].message.content)\n",
    "  response_json = json.loads(response.choices[0].message.content)\n",
    "  print(response_json[\"classification\"] + \": \" + response_json[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E4II3VlM62I0"
   },
   "source": [
    "We can see that some text is classified as sensitive even though it is open to the public in The National Archives. This is because it relates to legal matters or conflicts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2lZAYGIC6h0G"
   },
   "source": [
    "We will now define the context based on which we want the system to classify. We pass this context along with the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E9kMGCxSvkZM"
   },
   "outputs": [],
   "source": [
    "context = \"Text speaking monarchy are not sensitive. Every other text is sensitive\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aqb7mG0L7EvC"
   },
   "source": [
    "We now classify the texts based on the context. For this, we first provide the context and then in the other prompt, we tell the system to classify the text based on the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FcRYDBPGsJ_D",
    "outputId": "bdaafd20-8614-4644-ac7e-acf6bb925f58"
   },
   "outputs": [],
   "source": [
    "for text in texts:\n",
    "  response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "      {\"role\": \"system\", \"content\": \"The context is: '\" + context + \"'\"},\n",
    "      {\"role\": \"user\", \"content\": \"Given the context, classify as sensitive or not the text '\" + text + \"'. Format in the following JSON schema {'text': text, 'classification':value}\"}\n",
    "    ]\n",
    "  )\n",
    "  response_json = json.loads(response.choices[0].message.content)\n",
    "  print(response_json[\"classification\"] + \": \" + response_json[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_QfZBYLC7N-C"
   },
   "source": [
    "We can see that only the text that passed our context are classified sensitive."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
