{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dIQ9VN7DQQdU"
   },
   "source": [
    "##Prompt Engineering\n",
    "\n",
    "***Introduction***\n",
    "\n",
    "In this notebook, we are going to show how we can prompt engineer LLMs to analyze the text, from the Discovery, according to our need. This notebook is intended as a starting point, showing two examples prompt engineering, with the goal that you can then apply the same techniques to other analysis requirement.\n",
    "\n",
    "We will start by importing and installing required libraries. We will be using OpenAI library. Using OpenAI's API we will be using GPT-3.5. To use the API we will need OpenAI's API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z-lVwESg067L",
    "outputId": "bdbce678-57c1-494b-ea6b-89510c90aace"
   },
   "outputs": [],
   "source": [
    "%pip install -q openai\n",
    "%pip install -q requests\n",
    "%pip install -q json\n",
    "import json\n",
    "import re\n",
    "import requests\n",
    "from openai import OpenAI\n",
    "import helper_functions as hf\n",
    "client = OpenAI(api_key=\"API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "07Kpgz4hRQQu"
   },
   "source": [
    "## **Document classification**\n",
    "\n",
    "Text classification is the task of Natural Language Processing (NLP) in which text/document is assigned to one or more classes or categories. However, for this task the classes/categories have to be pre-defined as a label to which the texts are classified. In the scenario in which we have a set of descriptions but no lables, we can use LLMS to classify the required text to those descriptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L8UWkoEvVCeA"
   },
   "source": [
    "We will first define the set of descriptions to which we want our texts to be classified. For this we will use the Collections description from the Discovery. We will use the Discovery API as shown in the [Discovery API notebook](https://github.com/rae-drt/tna-exploratory-notebooks/blob/main/1-intro-to-discovery-api.ipynb). We will use a list of default ids for which we will request the description. If you want to add to the list some other record series, add their ids in the input box as list like separated by comma for example ['123', '124', '125']. If not, just press enter in the input box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E8T-peO0UAHL",
    "outputId": "73942249-c50d-49ca-f6ec-c898d4d370d1"
   },
   "outputs": [],
   "source": [
    "documentIDs = ['C13519', 'C13520', 'C13522']\n",
    "inputArray = input(\"Please enter the list of record series IDs\")\n",
    "if inputArray:\n",
    "  hf.append_IDs(documentIDs, inputArray)\n",
    "print(\"The list of records are:\", documentIDs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HfMUWWSUXX6T"
   },
   "source": [
    "Now we will use Discovery API to fetch their descriptions and store them in 'documents' dictionary with the key as the title of the record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pB4DQWD4KwST",
    "outputId": "d0c97856-26e8-47c5-c7cc-f01f55db1134"
   },
   "outputs": [],
   "source": [
    "documents = hf.populate_documents(documentIDs)\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w2we-BrdVKKk"
   },
   "source": [
    "We will now define the set of texts we want to classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textIDs = ['C3411937', 'C12215981', 'C5485074', 'C5485055']\n",
    "inputArray = input(\"Please enter the list of record IDs\")\n",
    "if inputArray:\n",
    "  hf.append_IDs(textIDs, inputArray)\n",
    "print(\"The list of records are:\", textIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Rfch1LwM5Tb"
   },
   "outputs": [],
   "source": [
    "texts = hf.populate_texts(textIDs)\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M4R1kNEDVZ3z"
   },
   "source": [
    "Now we will send this to GPT using the required prompt. For this, we first tell the system what it's role is. Here, it's role is being a helpful assistant. Now, we will pass the set of documents followed by the text with the prompt. In the prompt we ask the GPT just to classify the text and then return the result in JSON schema {'text': text, 'category':value} so that it can be computationally processed. For this example, since we haven't passed the labels, it will create its own set of label to which the documents closely associate and classify it to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "id": "te6J9LTTIpMX",
    "outputId": "acf7e7b4-74ac-465f-d596-4f64beadd811"
   },
   "outputs": [],
   "source": [
    "for text in texts:\n",
    "  response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "      {\"role\": \"user\", \"content\": \"Classify and return as JSON the text '\" + text + \"'. Format in the following JSON schema {'text': text, 'category':value}\"}\n",
    "    ]\n",
    "  )\n",
    "\n",
    "  response_json = json.loads(response.choices[0].message.content)\n",
    "  print(response_json[\"text\"] + \": \" + response_json[\"category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MS6Shgm1V-kb",
    "outputId": "04ff796c-752d-4ad4-e6fe-2106c96a2b2a"
   },
   "outputs": [],
   "source": [
    "for text in texts:\n",
    "  response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "      {\"role\": \"user\", \"content\": \"The set of documents are: \" + str(documents)},\n",
    "      {\"role\": \"user\", \"content\": \"Classify and return as JSON the text '\" + text + \"' to one of the documents given above. Format in the following JSON schema {'text': text, 'category':value}\"}\n",
    "    ]\n",
    "  )\n",
    "\n",
    "  response_json = json.loads(response.choices[0].message.content)\n",
    "  print(response_json[\"text\"] + \": \" + response_json[\"category\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TWAy_xbLobxv"
   },
   "source": [
    "## **Sensitivity classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3DOvfa-woqFP"
   },
   "source": [
    "Sensitivity classification is a task of NLP in which a text is binary (two classes) classified into \"sensitive\" and \"not sensitive\" depending upon the factors: text contains personal information, text is offensive in nature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2lZAYGIC6h0G"
   },
   "source": [
    "We will now define the context based on which we want the system to classify. We pass this context alomg with the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E9kMGCxSvkZM"
   },
   "outputs": [],
   "source": [
    "context = \"Text speaking monarchy are not sensitive. Every other text are sensitive\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AbHE3Dpk6sqt"
   },
   "source": [
    "We now classify the text without giving context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qpy35C73on8H",
    "outputId": "c9e12118-f28c-415a-abba-b5e92d6d7c42"
   },
   "outputs": [],
   "source": [
    "for text in texts:\n",
    "  response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "      {\"role\": \"user\", \"content\": \"Classify as sensitive or not the text '\" + text + \"'. Format in the following JSON schema {'text': text, 'classification':value, 'reason':value}\"}\n",
    "    ]\n",
    "  )\n",
    "\n",
    "  response_json = json.loads(response.choices[0].message.content)\n",
    "  print(response_json[\"classification\"] + \": \" + response_json[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E4II3VlM62I0"
   },
   "source": [
    "We can see that the some text is classified as sensitive even though it is open to public in The National Archives. This is because it relate to legal matters or conflicts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aqb7mG0L7EvC"
   },
   "source": [
    "We now classify the texts based on the context. For this, we first provide the context and then in the other prompt we tell the system to classify the text based on the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FcRYDBPGsJ_D",
    "outputId": "bdf9297d-6e82-4c11-ea0e-cac7bb0a32b5"
   },
   "outputs": [],
   "source": [
    "for text in texts:\n",
    "  response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "      {\"role\": \"system\", \"content\": \"The context is: '\" + context + \"'\"},\n",
    "      {\"role\": \"user\", \"content\": \"Given the context, classify as sensitive or not the text '\" + text + \"'. Format in the following JSON schema {'text': text, 'classification':value}\"}\n",
    "    ]\n",
    "  )\n",
    "  response_json = json.loads(response.choices[0].message.content)\n",
    "  print(response_json[\"classification\"] + \": \" + response_json[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_QfZBYLC7N-C"
   },
   "source": [
    "We can see that only the text that passed our context are classified sensitive."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
