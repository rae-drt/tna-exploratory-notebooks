{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Named Entity Recognition and Linking\n",
        "\n",
        "***Introduction***\n",
        "\n",
        "In this notebooks, we are going to show how we can analyze a text to find the mentions of named entities in it and link those named entities to their corresponding wikipedia page. This notebook is intended as a starting point, showing examples of using two pretrained models, with the goal that we can then use other models for different analysis of our text.\n",
        "\n",
        "We will start by importing and installing required libraries. We will be using Transformers library and pre-trained models maintained by Huggingface."
      ],
      "metadata": {
        "id": "VhavbuHMBqu4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will install Transformers"
      ],
      "metadata": {
        "id": "HU0QJeorE_dr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers seqeval[gpu]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "baBdBj4v4pQy",
        "outputId": "9dd4f585-6942-45fe-d7a2-085197bd201c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: seqeval[gpu] in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval[gpu]) (1.2.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval[gpu]) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval[gpu]) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval[gpu]) (3.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will import various libraries"
      ],
      "metadata": {
        "id": "ctQNyLMhFPG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch\n",
        "import helper_functions as hf\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizerFast, BertConfig, BertForTokenClassification\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification, AutoModelForSeq2SeqLM\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "JeJSMIt94so8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will import the models. For the task of Named Entity Recognition we will use base model of BERT NER \"bert-base-NER\" and for Linking we will use Facebook's mgenre-wiki."
      ],
      "metadata": {
        "id": "4duv7GVJFzZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
        "modelNER = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
        "tokenizerNEL = AutoTokenizer.from_pretrained(\"facebook/mgenre-wiki\")\n",
        "modelNEL = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/mgenre-wiki\").eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ZYV9MsDq421u",
        "outputId": "d7ad7c27-52a8-4c40-d719-92645a67decb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now extract the named entities. We do that by first defining a default sentence."
      ],
      "metadata": {
        "id": "ypeH_O-v4FOa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XV7ODqE_4AO3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "50b5ac8b-51b9-4635-814e-386a3bf94e3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter the id of the record you want to analyse. Leave it blank if you want to use the default text\n",
            "  Konni ZILLIACUS: British. A Russian Finn by birth, he came to notice through his Communist associations while working for the League of Nations in 1932. He was elected Labour MP for Gateshead in the 1945 General Election, but was expelled from the party in 1949 for persistently attacking party policy \n"
          ]
        }
      ],
      "source": [
        "record_id = \"C17023786\"\n",
        "inp_id = input(\"Please enter the id of the record you want to analyse. Leave it blank if you want to use the default text\")\n",
        "if inp_id != \"\":\n",
        "  record_id = inp_id\n",
        "sentence = hf.populate_texts(record_id)\n",
        "print(sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the form below, enter a  text you want to analyse. Leave it blank and press enter in the input box if you want to use the above default text."
      ],
      "metadata": {
        "id": "QlubiL3cRUat"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inp_text = input(\"Please enter a text you want to analyse. Leave it blank if you want to use the default text\")\n",
        "print(inp_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ovGtKxhTQ_yB",
        "outputId": "46c6b1ef-cb4c-44f3-bce0-11fed6398d2f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter a text you want to analyse. Leave it blank if you want to use the default text\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if inp_text != \"\":\n",
        "  sentence = inp_text\n",
        "print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "cyNKwCzZRnFK",
        "outputId": "0b19f268-2d7b-495e-871d-bbb2bff140c5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Konni ZILLIACUS: British. A Russian Finn by birth, he came to notice through his Communist associations while working for the League of Nations in 1932. He was elected Labour MP for Gateshead in the 1945 General Election, but was expelled from the party in 1949 for persistently attacking party policy \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we pass the sentence through our model and print extracted named entity."
      ],
      "metadata": {
        "id": "i_DGC7tw4NaI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = pipeline(\"ner\", model=modelNER, tokenizer=tokenizer)\n",
        "\n",
        "ner_results = nlp(sentence)\n",
        "named_entities = hf.getNE(ner_results)\n",
        "print(named_entities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Z-uLb2y94KZZ",
        "outputId": "f235e35f-d0a7-45bc-83a9-9020049a50c6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Konni ZIL', 'B-PER'), ('British', 'B-MISC'), ('Russian', 'B-MISC'), ('Finn', 'B-MISC'), ('Communist', 'B-ORG'), ('League of Nations', 'B-ORG'), ('Labour', 'B-LOC'), ('Gateshead', 'B-MISC'), ('General Election', 'B-MISC')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you have used the default example, you can see that the model has extracted \"Konni ZIL\" instead of \"Konni ZILLIACUS\". This is because the model breaks the words into smaller tokens and it was not able to predict the token \"IACUS\" is part of a name."
      ],
      "metadata": {
        "id": "UB7SAiyhTyjY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we predict the linking for the recognized named entity. It gives a list of Wikipedia page title for the named entity predicted earlier."
      ],
      "metadata": {
        "id": "JMsfOLxe4Qlv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = modelNEL.generate(\n",
        "    **tokenizerNEL(sentence, return_tensors=\"pt\"),\n",
        "    num_beams=10,\n",
        "    num_return_sequences=10,\n",
        ")\n",
        "\n",
        "tokenizerNEL.batch_decode(outputs, skip_special_tokens=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "NiRPHQU_4Xkf",
        "outputId": "45857cb9-f295-4d7f-d61e-11a5a1e1d379"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Conservative Party (UK) >> en',\n",
              " 'Member of Parliament (United Kingdom) >> en',\n",
              " 'Gateshead (UK Parliament constituency) >> en',\n",
              " 'Labour Party (UK) >> en',\n",
              " 'Politics of the United Kingdom >> en',\n",
              " 'House of Commons of the United Kingdom >> en',\n",
              " 'Member of parliament >> en',\n",
              " 'Parliament of the United Kingdom >> en',\n",
              " 'United Kingdom >> en',\n",
              " 'Conservative Party (United Kingdom) >> en']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, if we want to get the list for specific named entity then we pass the concerned named entity with [START] and [END] tags. The technical term for this is padding."
      ],
      "metadata": {
        "id": "eXiF-Jcy4bZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "sentence_pad = hf.get_pad(sentence, named_entities)\n",
        "print(sentence_pad)"
      ],
      "metadata": {
        "id": "txOXRrzx4d_r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "d1c5c432-40b3-4432-8544-de831be72d1b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Konni ZILLIACUS\n",
            "British\n",
            "Russian\n",
            "Finn\n",
            "Communist\n",
            "League of Nations\n",
            "Labour\n",
            "Gateshead\n",
            "General Election\n",
            "  [START]Konni ZILLIACUS[END]: British. A Russian Finn by birth, he came to notice through his Communist associations while working for the League of Nations in 1932. He was elected Labour MP for Gateshead in the 1945 General Election, but was expelled from the party in 1949 for persistently attacking party policy \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = input(sentence_pad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "KDnzScjeocWS",
        "outputId": "9de1c7d3-0986-4366-f1dd-cbdf43c53880"
      },
      "execution_count": 11,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  [START]Konni ZILLIACUS[END]: British. A Russian Finn by birth, he came to notice through his Communist associations while working for the League of Nations in 1932. He was elected Labour MP for Gateshead in the 1945 General Election, but was expelled from the party in 1949 for persistently attacking party policy \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text)\n",
        "if text != \"\":\n",
        "  sentence_pad = text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "HjyOQleGpAEX",
        "outputId": "d36d80ef-7c45-4b80-8546-105fc06546b0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = modelNEL.generate(\n",
        "    **tokenizerNEL(sentence_pad, return_tensors=\"pt\"),\n",
        "    num_beams=3,\n",
        "    num_return_sequences=3,\n",
        ")\n",
        "\n",
        "tokenizerNEL.batch_decode(outputs, skip_special_tokens=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "vV9HbVgz4gkZ",
        "outputId": "90b7436c-2881-4bbc-b15b-ee005c6ff507"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Konni Zilliacus >> en', 'Konni Zillacus >> en', 'Zilliacus >> en']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}