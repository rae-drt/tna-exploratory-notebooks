{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weird descriptions\n",
    "\n",
    "Ever come across a newspaper headline that makes you think someone was just sticking random words together, but it turns out it was a real (if somewhat unusual) event? This notebook takes inspiration from those headlines, and runs through the steps to find weird descriptions in Discovery series.\n",
    "\n",
    "As with always, start by importing the necessary libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q json\n",
    "%pip install -q wordfreq\n",
    "%pip install -q matplotlib\n",
    "%pip install -q numpy\n",
    "import json\n",
    "from wordfreq import word_frequency\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import helper_functions as hf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is \"weird\" anyway?\n",
    "\n",
    "The first step is to define metrics to measure weirdness. The inspiration of weird headlines, in particular with words that are used infrequently and in unusual combinations. The main series of notebooks showed, its fairly straightforwards to get all the descriptions from a series, so lets assume access to that data. This gives us a two main areas we can use: scoring based on how often words or combinations of words appear in the dataset, and scoring based on how many records a word appears in. \n",
    "\n",
    "#### Weirdness based on word frequency\n",
    "\n",
    "`record weirdness = average(average word weirdness from local, average word weirdness from global, average weirdness of word combinations)`\n",
    "\n",
    "Where: \n",
    " \n",
    "`word weirdness from local = 1 - (word frequency in all records in the series / total number of words in all records in the series)` - As a hypothetical example, if all records start \"The\", then have 100 different words that don't appear anywhere else, \"the\" should have a low score - its uncommon within individual records, but very common overall.\n",
    "\n",
    "`word weirdness from global` - There are datasets that provide word frequency in the English language which can be used to get a sense of how common a word is in general. \n",
    "\n",
    "`weirdness of word combinations = 1 - (pair frequency in all records in the series / toal number of pairs in the series)` - Looking at every adjacent pair of words in every record, how often are those two words next to each other? Similar to the word weirdness, if all descriptions start with \"The Parliament\", then have 100 different words that don't appear in other records, \"The Parliament\" should have a low score.\n",
    "\n",
    "\n",
    "These values are then averaged to accomodate for the length variability of record descriptions - some have lots of words, some have very few. If the weirdness value for each word was summed, then longer records would have a higher weirdness score than shorter records.\n",
    "\n",
    "#### Document occurrence weirdnes\n",
    "\n",
    "`record weirdness = average(document frequency weirdness of all words in the record)` - Documents with a higher average weirdness score with this metric are ones that contain words that appear in fewer records.\n",
    "\n",
    "Where:\n",
    "\n",
    "`document frequency weirdness of a word = 1 - (total number of records the word appears in/total number of documents)` - This is a measure of how many records a word appears in, with a higher score for words that appear in fewer records.\n",
    "\n",
    "Similar to the weirdness from global, the document frequency weirdness could be calculated from a larger dataset - for example, all records in the National Archives - before being used to calculate a record's weirdness.\n",
    "\n",
    "The key difference between this approach and weirdness based on word frequency is that records with a single word repeated frequently won't skew the score as much. For example, imagine a series of 100 records. If 50% of them used the word \"the\" once, and one of them had a really long description with the word \"parliament\" in it 100 times, the average weirdness from word frequency for both words would be the same. The document occurence weirdness, however, would be much higher for \"parliament\" than \"the\" - as it only accounts for the number of records a word appears in. Depending on the dataset, this may be a more reliable measure of weirdness. It will certainly be interesting to compare the two later on.\n",
    "\n",
    "## Lets start with getting the data\n",
    "\n",
    "As it was explained in detail in the [main series,](../1-intro-to-discovery-api.ipynb) this step of the process is in the `helper_functions.py` file to avoid repitition and making this notebook full of familiar code. Simply run the cell below to get the data - the default series it'll use is [`TITH`](https://discovery.nationalarchives.gov.uk/details/r/C254) but you can change that if you want. Note that really large series (eg `ADM`) will take a while to run, and may result in a timeout error from too many requests to the API. Note also that this cell is also going to print the current c-code its working on - this is to give a visual indication that it is running. \n",
    "\n",
    "To make it easy to work through and work on the weirdness score, the data gathered from this first step is going to look like this (note the nested nature as we are gathering every record from a series - sub-series will be stepped into using the child endpoint of the API):\n",
    "\n",
    "```JSON\n",
    "{\n",
    "    \"series\": \"TITH\",\n",
    "    \"total_records_count\": 100,\n",
    "    \"children\": [\n",
    "        {\n",
    "            \"series\": \"TITH 1\",\n",
    "            \"id\": \"discovery web id\",\n",
    "            \"description\": \"description of the record\",\n",
    "            \"children\" : [\n",
    "                {\n",
    "                    \"series\": \"TITH 1/1\",\n",
    "                    \"id\": \"discovery web id\",\n",
    "                    \"description\": \"description of the record\"\n",
    "                    \"children\": [ # and so on]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = hf.get_series_description(\"TITH\")\n",
    "\n",
    "print(json.dumps(data, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring the weirdness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weirdness of words (scoring based on word frequency)\n",
    "\n",
    "With the data gathered, lets start working on the score. The first step is to see what words are in the descriptions, their frequnecy, and thus their weirdness score. The new data will be stored a new key to the data structure `word_weirdness` at the same level as the `children` key. The data in it will look like this:\n",
    "\n",
    "```JSON\n",
    "{\n",
    "    \"series\": \"TITH\",\n",
    "    \"children\": [as before],\n",
    "    \"total_words\": 1000,\n",
    "    \"word_weirdness\": [\n",
    "        {\n",
    "            \"word\": \"the\",\n",
    "            \"occurences\": 100,\n",
    "            \"weirdness\": 0.9,\n",
    "            \"word_frequency\": 0.1\n",
    "        },\n",
    "        {for every word in the description}\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "Thanks to some builtins in Python, this is a fairly simple process. The first, and most complex step, is to build a single long list of every word in every description in the series. The complexity here is from the nested descriptions, hence the need for a recursive function. Once we have this list, the use of `set()` means we are looping throught the unique words in the list, and `.count()` counts the number of times each word appears in the main list.\n",
    "\n",
    "Word frequency, in this case, is being supplied by the [`wordfreq`](https://github.com/rspeer/wordfreq) package, which has a list of word frequencies in the English language, based on similar maths using a much larger dataset. You can read more about it in the link.\n",
    "\n",
    "These scores are based on all the descriptions in the data, not the descriptions of individual records, hence looping through every record and keeping a total score, rather than resetting the score each time. After this, the process for word pairs will be similar. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "word_weirdness = []\n",
    "\n",
    "def get_words(description):\n",
    "    if description[\"children\"] != \"No children\":\n",
    "        for child in description[\"children\"]:\n",
    "            get_words(child) # Recursion - if the record has children, call this function again with the child as the argument\n",
    "    if \"description\" in description: # The top level of the data doesn't have a description\n",
    "        if description[\"description\"] != None: # Sometimes the description is empty\n",
    "            for word in description[\"description\"].split(\" \"):\n",
    "                words.append(word)\n",
    "    return\n",
    "\n",
    "get_words(data)\n",
    "\n",
    "for unique_word in set(words):\n",
    "    word_weirdness.append(\n",
    "        {\n",
    "            \"word\": unique_word,\n",
    "            \"count\": words.count(unique_word),\n",
    "            \"weirdness\" : 1 - (words.count(unique_word) / len(words)),\n",
    "            \"word_frequency\": word_frequency(unique_word, \"en\", wordlist=\"large\")\n",
    "        }\n",
    "    )\n",
    "\n",
    "word_weirdness.sort(key=lambda x: x[\"weirdness\"], reverse=True) # This sorts the list in place, with the highest weirdness first\n",
    "\n",
    "data[\"total_words\"] = {\n",
    "    \"total\": len(words),\n",
    "    \"unique\": len(set(words))\n",
    "}\n",
    "data[\"word_weirdness\"] = word_weirdness\n",
    "\n",
    "print(json.dumps(data[\"word_weirdness\"], indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you scroll through the results of that cell, you'll notice that the data have an very [long tail](https://en.wikipedia.org/wiki/Long_tail), plotting that later will allow a better look at the data. Its also interesting to note that, as word frequency scores are based on the English language, many of these words results in really tiny scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document occurance weirdness\n",
    "\n",
    "Now we have a list of the unique words, we can calculate the document occurance weirdness, and add that to the data structure. This will be stored as the key `document_occurance_weirdness` along with the weirdness for each word. In this case, for each unique word we found we want to loop through each record description, see what words it has, and add 1 to the score if the unique word appears. Note that we don't add to the score if a word appears twice in a description - we're looking for how many descriptions the word appears in, so we only want to count it once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weirdness_score = 0\n",
    "\n",
    "def idf_calculator(record, word):\n",
    "    global weirdness_score\n",
    "    if record[\"children\"] != \"No children\":\n",
    "        for child in record[\"children\"]:\n",
    "            idf_calculator(child, word)\n",
    "    if \"description\" in record:\n",
    "        if record[\"description\"] != None:\n",
    "            if word in record[\"description\"].split(\" \"):\n",
    "                weirdness_score += 1\n",
    "    return weirdness_score\n",
    "\n",
    "for word in data[\"word_weirdness\"]:\n",
    "    weirdness_score = idf_calculator(data, word[\"word\"])\n",
    "    total_records_count = data[\"total_records_count\"]\n",
    "    data[\"word_weirdness\"][data[\"word_weirdness\"].index(word)][\"document_occurance_weirdness\"] = 1-(weirdness_score/total_records_count)\n",
    "    weirdness_score = 0\n",
    "\n",
    "print(json.dumps(data[\"word_weirdness\"], indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word pairs\n",
    "\n",
    "This is a similar process to the above, with the main switch being that instead of isolating every word, we are isolating every pair. The output data structure is going to look essentially the same. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = []\n",
    "pair_weirdness = []\n",
    "\n",
    "def get_pairs(description):\n",
    "    if description[\"children\"] != \"No children\":\n",
    "        for child in description[\"children\"]:\n",
    "            get_pairs(child) # Recursion - if the record has children, call this function again with the child as the argument\n",
    "    if \"description\" in description: # The top level of the data doesn't have a description\n",
    "        if description[\"description\"] != None: # Sometimes the description is empty\n",
    "            for i in range(len(description[\"description\"].split(\" \")) - 1):\n",
    "                pairs.append((description[\"description\"].split(\" \")[i], description[\"description\"].split(\" \")[i+1]))\n",
    "    return\n",
    "\n",
    "get_pairs(data)\n",
    "\n",
    "for unique_pair in set(pairs):\n",
    "    pair_weirdness.append(\n",
    "        {\n",
    "            \"pair\": unique_pair,\n",
    "            \"count\": pairs.count(unique_pair),\n",
    "            \"weirdness\" : 1 - (pairs.count(unique_pair) / len(pairs))\n",
    "        }\n",
    "    )\n",
    "\n",
    "pair_weirdness.sort(key=lambda x: x[\"weirdness\"], reverse=True) # This sorts the list in place, with the highest weirdness first\n",
    "\n",
    "data[\"pair_weirdness\"] = pair_weirdness\n",
    "\n",
    "print(json.dumps(data[\"pair_weirdness\"], indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The big thing to notice here is that almost every pair is fairly unique, getting a score close to 1. This is to be expected, with the number of possible pairs being so large. For example, for 100 unique words, there would be 100! (100 factorial) possible pairs. This is a very large number, and a description will only have a tiny fraction of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding data to the original structure\n",
    "\n",
    "Now scores for each word have been calculated, the weirdness score for each record (using the definitions earlier in the notebook) can be added to the data structure. They will be added in as new key/values for each record. Given that the different scores for weirdness are so different, the average of the three, and the three scores themselves are included. Remember that the scores are being averaged to accomodate for varying description lengths. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating a records document frequency weirdness is slightly more complex, needing its own function. This is simly as we need to loop through every word in the record as well as every word in the description to get the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_idf_calculator(description):\n",
    "    current_weirdness_score = 0\n",
    "    for word in description.split(\" \"):\n",
    "        for word_weirdness in data[\"word_weirdness\"]:\n",
    "            if word_weirdness[\"word\"] == word:\n",
    "                current_weirdness_score += word_weirdness[\"document_occurance_weirdness\"]\n",
    "    averaged_weirdness_score = current_weirdness_score / len(description.split(\" \"))\n",
    "    return averaged_weirdness_score\n",
    "\n",
    "def add_description_scores(record):\n",
    "    if record[\"children\"] != \"No children\":\n",
    "        for child in record[\"children\"]:\n",
    "            add_description_scores(child)\n",
    "    if \"description\" in record:\n",
    "        if record[\"description\"] != None:\n",
    "            record[\"word_weirdness_score\"] = (sum([word[\"weirdness\"] for word in word_weirdness if word[\"word\"] in record[\"description\"].split(\" \")])/len(record[\"description\"].split(\" \")))\n",
    "            record[\"word_frequency_weirdness_score\"] = (sum([word[\"word_frequency\"] for word in word_weirdness if word[\"word\"] in record[\"description\"].split(\" \")])/len(record[\"description\"].split(\" \")))\n",
    "            record[\"pair_weirdness_score\"] = (sum([pair[\"weirdness\"] for pair in pair_weirdness if pair[\"pair\"] in [(record[\"description\"].split(\" \")[i], record[\"description\"].split(\" \")[i+1]) for i in range(len(record[\"description\"].split(\" \")) - 1)]])/len(record[\"description\"].split(\" \")))/2\n",
    "            record[\"average_weirdness_score\"] = (record[\"word_weirdness_score\"] + record[\"word_frequency_weirdness_score\"] + record[\"pair_weirdness_score\"])/3\n",
    "            record[\"document_frequncy_score\"] = record_idf_calculator(record[\"description\"])\n",
    "\n",
    "add_description_scores(data)\n",
    "\n",
    "print(json.dumps(data, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the data\n",
    "\n",
    "To start exploring the data, the first thing is to show the most and least weird records are. This is done by a similar recursive function, looking for the highest and lowest scores for average weirdness from both word frequency and inverse document frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_weirdness = 0\n",
    "weirdest_record_by_document_frequency = {}\n",
    "weirdest_record_by_average_weirdness = {}\n",
    "least_weird_record_by_document_frequency = {}\n",
    "least_weird_record_by_average_weirdness = {}\n",
    "\n",
    "def find_weirdest_record(record, weridness_type, direction):\n",
    "    global current_weirdness\n",
    "    global weirdest_record_by_document_frequency\n",
    "    global weirdest_record_by_average_weirdness\n",
    "    global least_weird_record_by_document_frequency\n",
    "    global least_weird_record_by_average_weirdness\n",
    "    if direction == \"highest\":\n",
    "        current_weirdness = 0\n",
    "    elif direction == \"lowest\":\n",
    "        current_weirdness = float('inf')\n",
    "    \n",
    "    if record[\"children\"] != \"No children\":\n",
    "        for child in record[\"children\"]:\n",
    "            find_weirdest_record(child, weridness_type, direction)\n",
    "\n",
    "    if \"description\" in record and record[\"description\"] != None:\n",
    "        if weridness_type == \"document_frequncy_score\":\n",
    "            if direction == \"highest\" and record[\"document_frequncy_score\"] > current_weirdness:\n",
    "                current_weirdness = record[\"document_frequncy_score\"]\n",
    "                weirdest_record_by_document_frequency = record\n",
    "            elif direction == \"lowest\" and record[\"document_frequncy_score\"] < current_weirdness:\n",
    "                current_weirdness = record[\"document_frequncy_score\"]\n",
    "                least_weird_record_by_document_frequency = record\n",
    "        elif weridness_type == \"average_weirdness_score\":\n",
    "            if direction == \"highest\" and record[\"average_weirdness_score\"] > current_weirdness:\n",
    "                current_weirdness = record[\"average_weirdness_score\"]\n",
    "                weirdest_record_by_average_weirdness = record\n",
    "            elif direction == \"lowest\" and record[\"average_weirdness_score\"] < current_weirdness:\n",
    "                current_weirdness = record[\"average_weirdness_score\"]\n",
    "                least_weird_record_by_average_weirdness = record\n",
    "\n",
    "find_weirdest_record(data, \"document_frequncy_score\", \"highest\")\n",
    "print(\"The weirdest record by document frequency score is:\")\n",
    "print(json.dumps(hf.filter_children(weirdest_record_by_document_frequency), indent=4))\n",
    "\n",
    "find_weirdest_record(data, \"average_weirdness_score\", \"highest\")\n",
    "print(\"\\nThe weirdest record by average weirdness score is:\")\n",
    "print(json.dumps(hf.filter_children(weirdest_record_by_average_weirdness), indent=4))\n",
    "\n",
    "find_weirdest_record(data, \"document_frequncy_score\", \"lowest\")\n",
    "print(\"The least weird record by document frequency score is:\")\n",
    "print(json.dumps(hf.filter_children(least_weird_record_by_document_frequency), indent=4))\n",
    "\n",
    "find_weirdest_record(data, \"average_weirdness_score\", \"lowest\")\n",
    "print(\"\\nThe least weird record by average weirdness score is:\")\n",
    "print(json.dumps(hf.filter_children(least_weird_record_by_average_weirdness), indent=4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember the long tail in the word count scores? Lets plot that to see how long it is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_and_count = {}\n",
    "\n",
    "for word in data[\"word_weirdness\"]:\n",
    "    word_and_count[word[\"word\"]] = word[\"count\"]\n",
    "\n",
    "plt_word_counts, ax_word_counts = plt.subplots(figsize=(30, 30))\n",
    "ax_word_counts.bar(word_and_count.keys(), word_and_count.values())\n",
    "ax_word_counts.set_xlabel('Word')\n",
    "ax_word_counts.set_ylabel('Count')\n",
    "ax_word_counts.set_title('Word count')\n",
    "ax_word_counts.set_xticks([]) # This stops the x-ticks from being displayed - there are too many words to display them all\n",
    "ax_word_counts.yaxis.set_minor_locator(plt.MultipleLocator(1))\n",
    "ax_word_counts.yaxis.set_minor_formatter(plt.FuncFormatter(lambda x, _: int(x)))\n",
    "ax_word_counts.grid(which=\"minor\", axis=\"y\", linestyle=\"--\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yep, that's a long tail! A lot of words appear only once, with most appearing fewer than 10 times. Given that we have this data, what are the most common words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(data[\"word_weirdness\"][-10:], indent=4)) # we sorted with the highest weirdness first, so the last 10 are the least weird - and therefore the most common"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see how the weirdness score is distributed, lets plot that too. Here we're going to use a histogram, but with less refinement than other graphs, the goal is an overview of distribution of the scores. Remember that the record data is nested, so we'll need to step into the sub-series to get the scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_and_weirdness = {}\n",
    "\n",
    "def get_id_and_weirdness(record):\n",
    "    if record[\"children\"] != \"No children\":\n",
    "        for child in record[\"children\"]:\n",
    "            get_id_and_weirdness(child)\n",
    "    if \"id\" in record:\n",
    "        if \"average_weirdness_score\" in record:\n",
    "            id_and_weirdness[record[\"id\"]] = record[\"average_weirdness_score\"]\n",
    "\n",
    "get_id_and_weirdness(data)\n",
    "\n",
    "plt_id_and_weirdness, ax_id_and_weirdness = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "ax_id_and_weirdness.bar(id_and_weirdness.keys(), id_and_weirdness.values())\n",
    "ax_id_and_weirdness.set_xlabel('ID')\n",
    "ax_id_and_weirdness.set_xticks([])\n",
    "ax_id_and_weirdness.set_ylabel('Weirdness')\n",
    "ax_id_and_weirdness.set_title('Weirdness by ID')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the default series, this shows that most records are roughly the same weirdness. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see if that holds true for the document frequency weirdness, by plotting that too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_and_document_frequncy = {}\n",
    "\n",
    "def get_id_and_document_frequncy(record):\n",
    "    if record[\"children\"] != \"No children\":\n",
    "        for child in record[\"children\"]:\n",
    "            get_id_and_document_frequncy(child)\n",
    "    if \"id\" in record:\n",
    "        if \"document_frequncy_score\" in record:\n",
    "            id_and_document_frequncy[record[\"id\"]] = record[\"document_frequncy_score\"]\n",
    "\n",
    "get_id_and_document_frequncy(data)\n",
    "\n",
    "plt_id_and_document_frequncy, ax_id_and_document_frequncy = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "ax_id_and_document_frequncy.bar(id_and_document_frequncy.keys(), id_and_document_frequncy.values())\n",
    "ax_id_and_document_frequncy.set_xlabel('ID')\n",
    "ax_id_and_document_frequncy.set_xticks([])\n",
    "ax_id_and_document_frequncy.set_ylabel('Document Frequency')\n",
    "ax_id_and_document_frequncy.set_title('Document Frequency by ID')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some starter stats\n",
    "\n",
    "The weirdest record has been found, but a quick statistical analysis will give more confidence in saying \"its weird\". Lets find out the mean and standard deviation of the scores. If our record is more than 3 standard deviations from the mean, then it can be said to be statistically weird. As these are very widely used metrics, `numpy` makes this very approachable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_weirdness = np.mean(list(id_and_weirdness.values()))\n",
    "standard_deviation_weirdness = np.std(list(id_and_weirdness.values()))\n",
    "\n",
    "print(f\"The mean weirdness is {mean_weirdness} and the standard deviation is {standard_deviation_weirdness}. A record would need an average weirdness score of above {mean_weirdness + 3 * standard_deviation_weirdness} or below { mean_weirdness - 3 * standard_deviation_weirdness} to be an outlier.\")\n",
    "\n",
    "# Reprint the weirdest record\n",
    "\n",
    "print(json.dumps(hf.filter_children(weirdest_record_by_average_weirdness), indent=4))\n",
    "\n",
    "# see if the weirdest record is out by more than 3 standard deviations, else print the average weirdness score it would need to be an outlier\n",
    "\n",
    "if weirdest_record_by_average_weirdness[\"average_weirdness_score\"] > mean_weirdness + 3 * standard_deviation_weirdness or weirdest_record_by_average_weirdness[\"average_weirdness_score\"] < mean_weirdness - 3 * standard_deviation_weirdness:\n",
    "    print(\"The weirdest record is an outlier\")\n",
    "else:\n",
    "    print(f\"The weirdest record is not an outlier, it would need an average weirdness score of {mean_weirdness + 3 * standard_deviation_weirdness} or { mean_weirdness - 3 * standard_deviation_weirdness} to be one.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph looked more varied with the document frequency weirdness, so lets see if the stats are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_document_frequncy = np.mean(list(id_and_document_frequncy.values()))\n",
    "standard_deviation_document_frequncy = np.std(list(id_and_document_frequncy.values()))\n",
    "\n",
    "print(f\"The mean document frequency is {mean_document_frequncy} and the standard deviation is {standard_deviation_document_frequncy}. A record would need a document frequency score of above {mean_document_frequncy + 3 * standard_deviation_document_frequncy} or below { mean_document_frequncy - 3 * standard_deviation_document_frequncy} to be an outlier.\")\n",
    "\n",
    "print(json.dumps(hf.filter_children(weirdest_record_by_document_frequency), indent=4))\n",
    "\n",
    "if weirdest_record_by_document_frequency[\"document_frequncy_score\"] > mean_document_frequncy + 3 * standard_deviation_document_frequncy or weirdest_record_by_document_frequency[\"document_frequncy_score\"] < mean_document_frequncy - 3 * standard_deviation_document_frequncy:\n",
    "    print(\"The weirdest record is an outlier\")\n",
    "else:\n",
    "    print(f\"The weirdest record is not an outlier, it would need a document frequency score of {mean_document_frequncy + 3 * standard_deviation_document_frequncy} or { mean_document_frequncy - 3 * standard_deviation_document_frequncy} to be one.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the data\n",
    "\n",
    "After a lot of analysis work, it makes sense to save the data. We're going to save it as a JSON file, as that's the format we've been working with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data to a file called data.json\n",
    "\n",
    "with open(\"data.json\", \"w\") as file:\n",
    "    json.dump(data, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible next steps\n",
    "\n",
    "There are a couple of things we could do to improve these analysis: \n",
    "\n",
    "- Improve the formatting of the input text. If you look at the full list of words, you'll see duplicates where the same word is written in different cases, with punctuation, or often with HTML tags. Cleaning this up will give a more accurate picture of the data.\n",
    "- Removing common words. Words such as \"the\", \"and\", and \"of\", as examples, are all very common in English and will be standing out in the resulting scores. These are often called \"stop-words\". There are lists avaiable online, and an example where they are removed prior to analysis can be found in the [main series live demo notebook](../discovery.ipynb). \n",
    "- Using larger amounts of data. With limitations in place from the API, this notebook uses data from a single, small series. Compared to the rest of Discovery, this series could be highly unusual, or very normal. Using data from multiple series, or even the entire dataset may give a very different result.\n",
    "- Normalising the scores. The scores are all between 0 and 1, but the scales are different. Normalising the scores would allow for a more direct comparison between the different scores.\n",
    "\n",
    "These next steps would not change the process of the analysis, but would change the results. Before doing any of these, it is worth considering if they work towards the answer you are looking for. For example, making all words the same case looses sensitivity to different uses of the same word - it may be that a word is used as a proper noun in only one record; depending on your research question, this may be important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this notebook, we've gone through the full process of:\n",
    "1. From an inspiration, defining a metric to analyse our input data\n",
    "2. Gathering the correct parts of our data\n",
    "3. Calculating our metric for each record\n",
    "4. Visualising the results\n",
    "5. A little bit of statistical analysis\n",
    "6. Saving the data\n",
    "7. Considering next steps\n",
    "\n",
    "Or, what appeared to be a light hearted look at descriptions was sneakily a full data analysis project (if a small one). Hopefully this notebook has given you a good idea of how to approach a similar problem, and you had fun along the way."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
