{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics\n",
    "\n",
    "In the [drawing graphs](./2-drawing-graphs.ipynb) notebook, when plotting record start and end dates for different ships, the records started to show clusters around times when the Royal Navy used a ship name. This notebook explores that further. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q scikit-learn\n",
    "%pip install -q csv\n",
    "%pip install -q matplotlib\n",
    "%pip install -q numpy\n",
    "%pip install -q scipy\n",
    "%pip install -q pandas\n",
    "\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "from scipy import stats\n",
    "\n",
    "import pandas\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "This notebook will use the same dataset as the drawing graphs one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pandas.read_csv('ship_data.csv', sep=',', header=0)\n",
    "dataframe = pandas.DataFrame(data)\n",
    "print(dataframe.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, however, a few more modifications to the data are needed. The date-based columns are again converted to datetime objects, and the record duration is calculated again. As the statistical analysis run here will all only work with numerical data, some of the columns are dropped, and others are converted to numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberic_columns = dataframe[['startDate', 'endDate', 'record_duration', 'reference', 'description_length', 'ship']]\n",
    "\n",
    "numberic_columns['reference'] = dataframe['reference'].str.split(' ').str[1]\n",
    "numberic_columns['reference'] = pandas.to_numeric(numberic_columns['reference'].str.split('/').str[0])\n",
    "\n",
    "numberic_columns['startDate'] = pandas.to_datetime(dataframe['startDate']).values.astype(float)\n",
    "numberic_columns['endDate'] = pandas.to_datetime(dataframe['endDate']).values.astype(float)\n",
    "\n",
    "durations = []\n",
    "for duration in dataframe['record_duration']:\n",
    "    str(durations.append(duration.split(\" \")[0]))\n",
    "\n",
    "numberic_columns['record_duration'] = durations\n",
    "\n",
    "print(numberic_columns.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, a subset of the data (in this case, records to do with \"Boxer\") is isolated and made available. This smaller dataset will make it easier to read some of the example graphs and tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxer_data = numberic_columns[numberic_columns['ship'] == 'Boxer']\n",
    "boxer_data = boxer_data.drop(columns=['ship'])\n",
    "print(boxer_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dendrogram/Hierarchical Clustering\n",
    "\n",
    "To investigate whether the data are actually forming clusters, we can use a hierarchical clustering approach, and plot it on a dendrogram. \n",
    "\n",
    "This analysis looks at the data its given, and groups similar data together. For example, if two records started in 1850 and 1851, and the third in 1910, then the first two would be grouped together. This is comparison is then done across all records, using all the columns. This analysis is then repeated at different levels of similarity; allowing greater variation in the data within a cluster - for example, grouping a record that starts in 1850 with one that starts in 1870. This is repeated until all records are in one cluster. \n",
    "\n",
    "The results are then plotted on a dendrogram, shown in the next cell. In this example, the `ward` distance calculation method is used, which attempts to minimise the variance of clusters being joined. Dendrograms should be read similarly to family trees; the individual records are shown on the x axis at the bottom of the graph, with the branches representing the different clusters. The longer the branch, the more statistically significant the cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_dendro, ax_dendro = plt.subplots()\n",
    "dendrogram = sch.dendrogram(sch.linkage(boxer_data, method='ward'), ax=ax_dendro)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working up from the base of the dendrogram, we can see that the individual records quickly cluster into three distinct clusters, matching the expected outcome from the graph. The top half of the graph shows there may be just two clusters, which must be kept in consideration. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using these clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information about the number of clusters allows further analysis and visualisation of the clusters. \n",
    "\n",
    "The first step is assign each record to a cluster. The [`fcluster`](https://pythonguides.com/python-scipy-fcluster/) method from scipy uses the same hierarchical clustering method from the dendrogram, but here, the number of clusters is pre-specified. The output is a list, with the cluster number for each record, in order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wardlabel = fcluster(sch.linkage(boxer_data, method='ward'), 3, criterion='maxclust')\n",
    "\n",
    "print(wardlabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use this list of cluster numbers to colour records in scatter plots, for example. Here, we are drawing a pair, both with start date on the x-axis, one plotted against end date, and the other against duration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_cluster_scatter, (ax_cluster_scatter_1, ax_cluster_scatter_2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "ax_cluster_scatter_1.scatter(boxer_data['startDate'], boxer_data['endDate'], c=wardlabel, cmap='viridis')\n",
    "ax_cluster_scatter_1.set_xlabel('Start Date')\n",
    "ax_cluster_scatter_1.set_ylabel('End Date')\n",
    "ax_cluster_scatter_1.set_title('Start Date vs End Date')\n",
    "ax_cluster_scatter_2.scatter(boxer_data['startDate'], boxer_data['record_duration'], c=wardlabel, cmap='viridis')\n",
    "ax_cluster_scatter_2.set_xlabel('Start Date')\n",
    "ax_cluster_scatter_2.set_ylabel('Record Duration')\n",
    "ax_cluster_scatter_2.set_title('Start Date vs Record Duration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where before, plotting this data may have shown the 3 clusters, but might have not been clear. With the clusters coloured, the clusters the records belong to becomes much clearer. If the clusters are close together, the colour can be particularly useful in distinguishing between them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The start date vs end date graph for the Boxer data looks very similar to a straight line; a linear regression tests how closely a straight line compares to the data. This test provides you with a value for the slope of the line, and the y-intercept, giving enough information to plot the line. It also provides an r-value and p-value. The p-value represents the probability that the slope of the line is 0. The r-value is the Pearson correlation coefficient, which, when squared, becomes the coefficient of determination. This value represents the proportion of the variance in the dependent variable that is predictable from the independent variable - testing to see if the line predicts the data well.\n",
    "\n",
    "This test is available via SciPy, and compares two lists of equal length. With a small amount of extra work, you can then plot the line onto the scatter graph. This next cell does all of these steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "\n",
    "for index, row in boxer_data.iterrows():\n",
    "    x.append(row['startDate'])\n",
    "    y.append(row['endDate'])\n",
    "\n",
    "regression = stats.linregress(x, y)\n",
    "print(regression)\n",
    "\n",
    "print(\"R squared: \" + str(regression.rvalue ** 2))\n",
    "\n",
    "plt_regression, ax_regression = plt.subplots()\n",
    "ax_regression.scatter(x, y, c=wardlabel, cmap='viridis')\n",
    "line_y = [regression.slope * i + regression.intercept for i in x]\n",
    "ax_regression.plot(x, line_y, color='red')\n",
    "ax_regression.set_xlabel('Start Date')\n",
    "ax_regression.set_ylabel('End Date')\n",
    "ax_regression.set_title('Start Date vs End Date')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The R-squared value for the Boxer data ends up being 0.999, very close to 1, indicative of a very strong linear relationship. Note that this might be somewhat expected - the graph is start date vs end date, so the two are directly related."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All the data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than drawing scatter diagrams for each combination of variables, it is possible to draw a single scatter plot of all the data at once, while keeping as much of the information as possible. This is achieved through a scatter diagram based on a Principal Component Analysis (PCA).\n",
    "\n",
    "Plotting a PCA is similar to plotting a 2-d scatter plot, but taking into account multiple dimensions. Imagine a 3-d scatter plot, where the points all formed a perfect sphere - plotting a silhouette in two dimensions, the graph would look like a circle. A PCA achieves this with as many dimensions as supplied (with dimensions here referring to columns in the data, or variables). PCAs aim to show as much variation in the data as possible while doing this: for example, if 3d-scatter looked like a rugby ball, then the projection would look more like an oval. To make PCAs easier to read, variables from the original data can be drawn onto the scatter plot as arrows - with longer arrows generally representing a stronger effects. \n",
    "\n",
    "The 'components' in the name of the analysis relates to these factors used to project the data. A PCA aims to reduce the number of dimensions (or columns), while keeping as much variation as possible. Thus, if two dimensions are very similar, the PCA keep them as a single component."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is another tweak of the data - where previously we were working with the numeric only data relating to Boxer, we need a numeric only dataset for all ships. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberic_columns = numberic_columns.drop(columns=['ship'])\n",
    "\n",
    "print(numberic_columns.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step in plotting the PCA is to calculate the PCA itself. The components are then made available. The loadings (known as such as they show how much the variable loads onto the component) are calculated using this information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "components = pca.fit_transform(numberic_columns)\n",
    "loadings = pca.components_.T * np.sqrt(pca.explained_variance_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These components are then used to plot the PCA. The scatter plot is drawn, and the loadings are drawn as arrows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_pca, ax_pca = plt.subplots(figsize=(15, 15))\n",
    "ax_pca.scatter(components[:, 0], components[:, 1], c=numberic_columns['reference'], cmap='viridis')\n",
    "for i, (x, y) in enumerate(zip(loadings[:, 0], loadings[:, 1])):\n",
    "    ax_pca.arrow(0, 0, x, y, color='r', alpha=0.5)\n",
    "    ax_pca.text(x, y, numberic_columns.columns[i], fontsize='12', ha='right')\n",
    "ax_pca.set_xlabel('PC1')\n",
    "ax_pca.set_ylabel('PC2')\n",
    "ax_pca.set_title('PCA')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different components in the PCA will have stronger or weaker effects on the outcome, and some may have so little effect that they are statistically insignificant. A scree plot shows their different levels with the components shown on the x-axis and level of effect they have on the y-axis. Higher numbered components have less effect on the PCA, leading to the slope of the graph, and the name 'scree'-plot - they look like the scree slope on a mountain. \n",
    "\n",
    "There are two ways to read a scree plot: \n",
    "- Look for an 'elbow' - typically, a scree plot will have a point where it goes from a steep slope to a shallow one. To determine which factors to keep, look for this point, and keep all factors to the left. \n",
    "- Take all factors with an effect of 1 or above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_values = np.arange(pca.n_components_) + 1\n",
    "fig_pca_variance, ax_pca_variance = plt.subplots()\n",
    "ax_pca_variance.plot(pc_values, pca.explained_variance_ratio_, 'ro-', linewidth=2)\n",
    "ax_pca_variance.set_title('Scree Plot')\n",
    "ax_pca_variance.set_xlabel('Principal Component')\n",
    "ax_pca_variance.set_ylabel('Proportion of Variance Explained')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this scree plot, we can see that there really is only 1 component causing any variation. In this example, this is almost certainly a result of the artificial nature of the data - we have chosen to keep start and end date, and have calculated record duration from these. These values are almost certainly going to be working together as the only component. With more complex datasets, scree plots can become more useful, variable, and require more careful consideration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further steps and conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook only scratches the surface of the statistical analysis that can be run, and does not go into much detail on the methods used. Depending on what has interested you about this notebook, there are a few different directions you could go in:\n",
    "\n",
    "- If the possibility of grouping together records in clusters has interested you, there are other methods of clustering, with different strengths and weaknesses depending on what data are available.\n",
    "\n",
    "- If you have a research question but the data has missing values, there are techniques to fill in these gaps, and test whether this has affected the results.\n",
    "\n",
    "- If being able to analyse large datasets has opened new research questions for you to investigate, there are various statistical methods available, simply needing the right question to be asked."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
